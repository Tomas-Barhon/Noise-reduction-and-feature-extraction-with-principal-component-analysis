\chapter*{Bachelor's Thesis Proposal}

\begin{tabular}{lp{10.1cm}}
	\hline
	\textbf{Author}         & \href{mailto:\Email}{\AutorDP}       \\
	\textbf{Supervisor}     & \href{mailto:\EmailSup}{\Supervisor} \\
	\textbf{Proposed topic} & \Bookname                            \\
	\hline
\end{tabular}

\bigskip

\small
\paragraph{Motivation}

Crypto assets have always been exceptionally volatile compared to traditional assets such as stocks or gold. The historical
window is relatively short, thus modeling their price or volatility proposes quite a difficult challenge. It is generally believed
that noise in any data decreases the precision of predictions. This effect might be reduced, which will improve the
performance of traditional models that are used for cryptocurrency price modeling.

The main motivation for researching this topic is that there is still an ongoing discussion about the role of different features
in crypto pricing dynamics. (Kukacka; Kristoufek 2023) have shown that a lot of the pricing dynamic emerges from complex
interactions between fundamental and speculative components. They also show the different correlations between all of the
explanatory variables which have a direct connection to principal component analysis. It is crucial to study the real impact of
those variables in different models as many of them might turn out to be obsolete.

There is currently little use of this dimensionality reduction technique in the academic literature about cryptocurrencies.
However, for more traditional financial series this technique is already quite established as a preprocessing technique to
reduce noise and dimensionality from which financial data inherently suffer (Chowdhury, U. ; Chakravarty, S. and Hossain,
M. 2018). Moreover (Bouri, E.; Kristoufek, L.; Ahmad, T. et al. 2022) studied the effect of microstructural noise on
idiosyncratic volatility in cryptocurrencies which further supports the need for a technique that will mitigate this effect on the
predictions.

The research will address the problem of variable selection for different types of predictive models with respect to the
analysis of the principle components aiming to reduce the dimensionality and simultaneously increase precision. The second
question is whether it is more appropriate to transform the high dimensionality with PCA into lower dimensionality or
simply omit the variables with high multicollinearity from the models. These approaches are fundamentally different and the
answer is not clear.

\paragraph{Methodology}

The data will come from various sources because the aim is to look at all the possible variables even if they might not seem
useful at first glance. As already mentioned the dynamic is driven by a lot of completely different effects. Most of it will be
collected from: coinmetrics.io, studio.glassnode.com, and for macroeconomic indicators https://fred.stlouisfed.org/. Some of
the data might need to be interpolated to daily observations. Lastly, the observations will need to be sliced to different
window sizes and shifted by one so that the predictions can be made for the next day with the data available on that day.

Afterward, the multicollinearity in the data will be examined and different approaches to solve it will be used. The two main
ones are using only a smaller set of uncorrelated variables (simple dimensionality reduction) and the second being employing
PCA transformation to preserve a predefined threshold of variance or directly targeting the number of principal components.

All the different setups will be compared across three models: linear regression, SVM, and LSTM neural network. The
hypothesis is that PCA transformation will substantially lower the measured errors for linear regression and SVM although
for LSTM it will result in lower performance as it will only decrease the capacity of the model as the model is powerful
enough to create such uncorrelated features without the PCA transformation.

\paragraph{Expected Contribution}

Existing research agrees that financial data and especially cryptocurrency data are significantly affected by noise. The main
goal is to extend the research on the topic of variable selection for algorithmic trading models as there are still a lot of
unanswered questions. It will most likely become clearer which approach to dimensionality reduction is the most efficient
concerning cryptocurrencies.

Also, not only the underlying pricing dynamics will be detected but the results can be used for investors that are trying to
lower their risk of loss which is relatively high in crypto markets. The effect of having a more stable and precise model
might significantly cut the transaction costs that are associated with more frequent exchanges as the predictions will become
less volatile. That is a desirable property needed to maximize profit and increase credibility towards its customers.



\paragraph{Core bibliography}


\begin{enumerate}
	\item[]Kukacka, J., \& Kristoufek, L. (2023). Fundamental and speculative components of the cryptocurrency pricing
	dynamics (Vol. 9). Financial Innovation.
	\item[]Kristjanpoller, W., \& Minutolo, M. C. (2018). A hybrid volatility forecasting framework integrating GARCH, artificial
	neural network, technical analysis and principal components analysis (Vol. 109). Expert Systems with Applications.
	\item[]Chowdhury, U. N., Chakravarty, S. K., \& Hossain, M. T. (2018). Short-Term Financial Time Series
	Forecasting Integrating Principal Component Analysis and Independent Component Analysis with
	Support Vector Regression (Vol. 6).
	\item[]Bouri, E., Kristoufek, L., , \& Shahzad, S. J. H. (2022). Microstructure noise and idiosyncratic volatility
	anomalies in cryptocurrencies. Springer Link. https://doi.org/10.1007/s10479-022-04568-9
	\item[]Rea, A., \& Rea, W. (2016). How many components should be retained from a multivariate time series
	PCA?. arXiv preprint arXiv:1610.03588.
\end{enumerate}


\vfill
\begin{table}[!hbp]
	\begin{tabular}{lr}
		
		\begin{tabular}{p{3.5cm}}
			\hline \hspace{1cm} Author
		\end{tabular}
		
		\hspace{5.5cm}
		
		\begin{tabular}{p{3.5cm}}
			\hline \hspace{0.8cm} Supervisor
		\end{tabular}
		
		
	\end{tabular}
\end{table}

\normalsize





